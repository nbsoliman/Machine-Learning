{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CSCR 421 Problem Set 3\n",
    "# Due Wednesday, October 13, 2021 @ 11:59pm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read *all* cells carefully and answer all parts (both text and missing code)\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:\n",
    "\n",
    "* For your submission please rename the folder with ***student_id*** (***DO NOT RENAME THE ZIP, RENAME THE FOLDER, THEN CREATE THE ZIP***), then create it into a .zip file. Other formats will not be accepted. Makes sure that the notebook in the folder is still called Homework03,that folder is in the folder which is named after you student ID.\n",
    "* Keep the data folder in the Homework03 folder and make sure it is there when you submit your homework. \n",
    "* No late submissions accepted unless you have slip days remaining.\n",
    "* This is an individual assignment. While you are welcome to discuss general concepts together andon the discussion board your solutions must be yours and yours alone.\n",
    "* SHOW YOUR WORK.\n",
    "* You may not import any other libraries than the ones already imported. \n",
    "* If you want to create helper functions, add them to the top of the already created code cells. Please do not add any other code cells.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Enter your information below:\n",
    "\n",
    "<div style=\"color: #000000;background-color: #EEEEFF\">\n",
    "    Your Name (submitter): Nicholas Soliman<br>\n",
    "Your student ID (submitter): 326009195\n",
    "</div>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEFF\">\n",
    "    <font size=+2>Part I: Regression</font>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d = pd.read_csv('data/Hitters.csv')\n",
    "df = pd.DataFrame(data=d)\n",
    "df.dropna(inplace=True)\n",
    "features = df.loc[:, df.columns != 'NewLeague']\n",
    "label = df['NewLeague']\n",
    "categorical = features.select_dtypes(exclude = ['int64', 'float64'])\n",
    "categorical = pd.get_dummies(categorical, columns=['League', 'Division'])\n",
    "categorical = categorical.loc[:, categorical.columns != 'Player']\n",
    "numerical = features.select_dtypes(include = ['int64', 'float64'])\n",
    "features = pd.concat([categorical, numerical], axis=1)\n",
    "label.replace({'A': 0, 'N': 1}, inplace=True)\n",
    "x = features\n",
    "y = label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "    <font size=+2>Question 1:</font>\n",
    "    \n",
    "<font size=+1>(1)</font> Using 80% of the data as a training set and 20% as a testing set, please implement a ridge regression and a lasso regularization logistic regression model for Hitters dataset (from HW2). Please describe your hyperparameter tuning procedures.\n",
    "\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "<font size=+1>(2)</font> Please provide the coefficients for each feature for both models. Are they the same? Are they different? Why?\n",
    "\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "<font size=+1>(3)</font> Please plot the ROC curve for both models. What are the area under the curve measurements?\n",
    "\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFFFEE\">\n",
    "<font size=+1>(4)</font> How do these compare to the models from HW 2? Please describe similarities and differences.\n",
    "\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color: #000000;background-color: #FFEEFF\">\n",
    "    <font size=+2>Part II: Classification Trees</font>\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "On this problem, you'll be coding up regression and classification trees from scratch. Trees are a special class of graphs with only directed edges sans any cycles. They fall under the category of directed acyclic graphs or DAGs. So, trees are DAGs where each child node has only one parent node.  \n",
    "\n",
    "Since trees are easy to design recursively, it is super important that you're familiar with **recursion**. So, it is highly recommended that you brush up on recursion and tree-based search algorithms such as depth-first search (BFS) and breadth-first search (BFS). \n",
    "\n",
    "### Instructions\n",
    "- You are **NOT** allowed to use machine learning libraries such as scikit-learn to build regression and classification trees for this assignment.\n",
    "- You are required to complete the functions defined in the code blocks following each question. Fill out sections of the code marked `\"YOUR CODE HERE\"`.\n",
    "- Once you've filled out your solutions, submit the notebook on Canvas.\n",
    "- Do **NOT** forget to type in your name and UIN at the beginning of the notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a suggested sequence of steps you may want to think along for building regression and classification trees.\n",
    "\n",
    "1. **Defining a criteria for splitting.**\n",
    "    1. This criteria assigns a score to a split.\n",
    "    1. For regression trees, this would be the mean squared error.\n",
    "    2. For decision trees, this would be the Gini index or entropy.\n",
    "2. **Create the split.**\n",
    "    1. Split the dataset by iterating over all the rows and feature columns.\n",
    "    2. Evaluate all the splits using the splitting criteria.\n",
    "    3. Choose the best split.\n",
    "3. **Build the tree.**\n",
    "    1. Terminal nodes: decide when to stop growing a tree. This would be the maximum allowed depth of the tree or when a leaf is empty or has only 1 element.\n",
    "    2. Recursive splitting: once a split is created, you can split it further recursively by calling the same splitting function on it.\n",
    "    3. Building a tree: create a root node and apply recursive splitting on it.\n",
    "4. **Make predictions with the tree.**\n",
    "    1. For a given data point, make a prediction using the tree."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (1) Growing a maximum-depth regression tree\n",
    "\n",
    "The recursive procedure for growing a deep regression tree is illustrated in the figure below. We begin (on the left) by fitting a stump to the original dataset. As we move from left to right the recursion proceeds, with each leaf of the preceding tree split in order to create the next, deeper tree. As can be seen in the rightmost panel, a tree with maximum depth of four is capable of representing the training data perfectly.  \n",
    "\n",
    "![Fig14_07.jpg](data/Fig14_07.jpg)\n",
    "\n",
    "**Peform the experiment shown in the figure by coding up a recursively defined regression tree. Instead of reproducing the plot, measure and plot the mean squared error (MSE) at each depth of your tree.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csvname = 'data/noisy_sin_subsample_2.csv'\n",
    "data_regress = np.loadtxt(csvname, delimiter = ',')\n",
    "data_regress = np.array([[x, y] for x,y in zip(*data_regress)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.scatter(data_regress[:, 0], data_regress[:, 1])\n",
    "plt.xlabel(\"Features, x\")\n",
    "plt.ylabel(\"Target values, y\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Build the regression tree in the `TreeRegressor` class**.  \n",
    "***TIP:*** *If you are smart about building the regression tree, you can reuse most of the code for building the classification tree in Question 2.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class TreeRegressor():\n",
    "    def __init__(self, data, max_depth=1):\n",
    "        self.data = data # last element of each row in data is the target variable\n",
    "        self.max_depth = max_depth # maximum depth\n",
    "        # YOU MAY ADD ANY OTHER VARIABLES THAT YOU NEED HERE\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Build the recursive \n",
    "    def build_tree(self):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Calculate the mean squared error for a split dataset\n",
    "    def mean_squared_error(self, splits):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self, node, depth):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self, data):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Outcome of the terminal group\n",
    "    def to_terminal(self, group):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Split a dataset based on an attribute and an attribute value\n",
    "    def test_split(self, index, value, data):\n",
    "        ## YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Don't forget to create a method to make predictions using your tree. You may create a separate function for it or make it a part of the `TreeRegressor` class.  \n",
    "**Plot the MSE at each depth of your tree**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict(node, row):\n",
    "    #YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mse_depths = []\n",
    "for depth in range(1, 5):\n",
    "    regressor = TreeRegressor(data_regress, depth)\n",
    "    tree = regressor.build_tree()\n",
    "    mse = 0.0\n",
    "    for data_point in data_regress:\n",
    "        mse += (data_point[1] - predict(tree, data_point))**2\n",
    "    mse_depths.append(mse/len(data_regress))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the MSE\n",
    "plt.figure()\n",
    "plt.plot(mse_depths)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### (2) (50 points)\n",
    "\n",
    "## Growing a two-class classification tree\n",
    "\n",
    "The figure below shows the growth of a tree to a maximum depth of seven on a two-class classification dataset. As the tree grows, note how many parts of the input space do not change as leaves on the deeper branches become *pure*. By the time we reach a maximum depth of seven, there is considerable overfitting. \n",
    "\n",
    "![Fig14_11.jpg](data/Fig14_11.jpg)\n",
    "\n",
    "**Perform the experiment shown in figure by coding up a recursively defined two-class classification tree. Instead of reproducing the plot, measure and plot the classification accuracy at each depth of your tree.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csvname = 'data/new_circle_data.csv' # Place the CSV file in the same directory as this notebook\n",
    "data_class = np.loadtxt(csvname, delimiter = ',')\n",
    "data_class = np.array([[x1, x2, y] for x1,x2,y in zip(*data_class)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.scatter(data_class[:, 0], data_class[:, 1], c=-data_class[:, 2], cmap='bwr')\n",
    "plt.xlabel(\"Features, x1\")\n",
    "plt.ylabel(\"Features, x2\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TreeClassifier is a derived class of TreeRegressor\n",
    "\n",
    "class TreeClassifier(TreeRegressor):\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self, splits, classes):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Select the best split point for a dataset\n",
    "    def get_split(self, data):\n",
    "        ## YOUR CODE HERE\n",
    "    \n",
    "    # Outcome of the terminal group\n",
    "    def to_terminal(self, group):\n",
    "        ## YOUR CODE HERE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Don't forget to create a method to make predictions using your tree.  \n",
    "**Plot the classification accuracy at each depth of your tree.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## YOUR CODE HERE\n",
    "accuracy_depths = []\n",
    "for depth in range(1, 8):\n",
    "    classifier = TreeClassifier(data_class, depth)\n",
    "    tree = classifier.build_tree()\n",
    "    correct = 0.0\n",
    "    for data_point in data_class:\n",
    "         correct += float(data_point[2] == predict(tree, data_point))\n",
    "    accuracy_depths.append(correct/len(data_class))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the MSE\n",
    "plt.figure()\n",
    "plt.plot(accuracy_depths)\n",
    "plt.xlabel(\"Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "4e7d7b88fe9e1670f7e8ef5777cab33ffeab5b31ad2df29b9051f9df525a9039"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}